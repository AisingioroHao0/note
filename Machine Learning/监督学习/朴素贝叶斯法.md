# 朴素贝叶斯

## 算法流程

获取独立同分布数据x，y，x是n维向量，y为标量，取值范围（$c_1,...,c_k$）

- 学习先验概率分布$P(y)$

- 学习条件概率分布$P(x|y)$

  朴素贝叶斯法对条件概率分布作了条件独立性假设。假设每一维度的特征是不相关的，那么就可以拆解连乘求得条件概率吧

$$
P(x|y)=\prod_{i=1}^{n}P(x[i]|y)
$$

- 分类时计算后验概率，根据贝叶斯定理,计算x条件下y最有可能等于什么.

  
  $$
  P(y|x)=\frac{P(x|y)P(y)}{\sum_{i=1}^k P(x|c_i)P(c_i)}
  $$
  理解：首先算出x的概率吧是多少，然后算出是x中y的占比是多少

- 选出P(y|x)取值最大的y

## 后验概率最大化的含义

朴素贝叶斯法将实例分到后验概率最大的类中，等价于经验风险最小化

![image-20230310175402210](./%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95.assets/image-20230310175402210.png)

## 参数估计

### 极大似然估计

正常计算得到概率，数量求比

![image-20230312230816580](./%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95.assets/image-20230312230816580.png)

## 学习与分类算法

![image-20230312231007208](./%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95.assets/image-20230312231007208.png)

### 贝叶斯估计

极大似然估计可能会出现要估计的概率值为0的情况，这时会影响后验概率的计算结果，使分类产生偏差。解决这一问题的方法使采用贝叶斯估计。

![image-20230312231409951](./%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95.assets/image-20230312231409951.png)

![image-20230312231335166](./%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95.assets/image-20230312231335166.png)

$\lambda=1$此时称为拉普拉斯平滑

![image-20230312231500677](./%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95.assets/image-20230312231500677.png)
