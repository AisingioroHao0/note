## 基于分数的扩散模型

[Song and Ermon](https://arxiv.org/abs/1907.05600)提出与扩散模型由很多相似之处的不同类型的生成模型。基于分数的模型使用分数匹配和 Langevin 动力学处理生成学习。

分数匹配是指对对数概率密度函数（也称为分数函数）的梯度进行建模的过程。 Langevin 动力学是一个迭代过程，可以仅使用其评分函数从分布中抽取样本。
$$
\mathbf{x}_t=\mathbf{x}_{t-1}+\frac{\delta}{2}\nabla_x\log p\left(\mathbf{x}_{t-1}\right)+\sqrt{\delta}\epsilon,\quad\text{where}\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})
$$

- $\delta$是总步骤数。

假设我么能有一个概率密度函数$p(x)$并且我们定义了分数方程$\nabla_x \log p(x)$。我们可以训练一个神经网络$s_\theta$，在没有首先估计$p(x)$的情况来估计$\nabla_x \log p(x)$。训练的目标可以写为
$$
\mathbb{E}_{p(\mathbf{x})}[\|\nabla_{\mathbf{x}}\log p(\mathbf{x})-\mathbf{s}_{\theta}(\mathbf{x})\|_2^2]=\int p(\mathbf{x})\|\nabla_{\mathbf{x}}\log p(\mathbf{x})-\mathbf{s}_{\theta}(\mathbf{x})\|_2^2\mathrm{d}\mathbf{x}
$$
然后通过使用 Langevin 动力学，我们可以使用近似得分函数直接从p(x) 采样。

### 条件噪声分数网络(Noise Conditional Score Networks NCSN)

到目前为止的问题：估计的得分函数在低密度区域通常不准确，那里只有很少的数据点可用。因此，使用 Langevin 动力学采样的数据质量并不好。

他们的解决方案是用噪声扰乱数据点，然后在噪声数据点上训练基于分数的模型。事实上，他们使用了多尺度的高斯噪声扰动。
因此，添加噪声是使 DDPM 和基于分数的模型都起作用的关键。

![score-based](./%E5%88%86%E6%95%B0%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.assets/score-based.png)

在数学上，给定一个数据分布$p(x)$，我们添加一个高斯噪声$\mathcal{N}(\mathbf{0},\sigma_i^2I)\text{where}\ i=1,2,\cdots,L$来获取噪声分布
$$
p_{\sigma_i}(\mathbf x)=\int p(\mathbf y)\mathcal N(\mathbf x;\mathbf y,\sigma_i^2I)\mathrm dy
$$
然后我们训练一个网络$s_\theta(x,i)$，估计分数函数$\nabla_x \log d_{\sigma_i}(x)$条件噪声分数网络。训练目标是费雪散度[Fisher divergences](https://en.wikipedia.org/wiki/Fisher_information_metric)的加权和
$$
\sum\limits_{i=1}^L\lambda(i)\mathbb{E}_{p_{\sigma_i}}(\mathbb{x})[\|\nabla_\mathbb{x}\log p_{\sigma_i}(\mathbb{x})-\mathbb{s}_\theta(\mathbb{x},i)\|_2^2]
$$

### 通过随机微分方程的分数生成模型 stochastic differential equations(SDE)

[Song et al. 2021](https://arxiv.org/abs/2011.13456)提出基于分数的模型与扩散模型的连接。为了封装NCSNs和DDPMs在相同的结构下，提出了以下的方案。

不使用有限数量的噪声分布来扰动数据，而是使用一个连续的分布，这些分布根据扩散过程随时间的推移而演变。这个过程由一个规定的随机微分方程（SDE）来模拟，不依赖于数据，也没有可训练的参数。通过逆转这个过程，可以生成新的样本。

![score-sde](./%E5%88%86%E6%95%B0%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.assets/score-sde.png)

我们可以将扩散过程${x(t)}_{t \in [0,T]}$定义为一个SDE
$$
\mathrm{dx}=\mathbf{f}(\mathbf{x},t)\mathrm{d}t+g(t)\mathrm{d}\mathbf{w}
$$

- w是[Wiener process](https://en.wikipedia.org/wiki/Wiener_process) (a.k.a., [Brownian motion](https://en.wikipedia.org/wiki/Brownian_motion))
- $f(.,t)$是一个向量值函数，叫作$x(t)$的漂移系数drift coefficient
- $g(.)$是一个标量函数，被称作$x(t)$的扩散系数

SDE通常有 唯一强解。

SDE 的灵感来自布朗运动，其中许多粒子在介质内随机移动。粒子运动的这种随机性模拟了数据上的连续噪声扰动。

在对原始数据分布进行足够长时间的扰动后，扰动后的分布变得接近易处理的噪声分布。
要生成新样本，我们需要反转扩散过程。选择的 SDE 具有相应的封闭形式的反向 SDE：
$$
\mathrm{dx}=[\mathbf{f}(\mathbf{x},t)-g^2(t)\nabla_\mathbf{x}\log p_t(\mathbf{x})]\mathrm{d}t+g(t)\mathbf{d}\mathbf{w}
$$
为了计算SDE的反转过程，我们需要估计分数函数$\nabla_x\log p_t(x)$。这是通过使用基于分数的模型$x_\theta(x,i)$和朗格万动力学来完成的。训练目标是费雪散度的连续组合
$$
\mathbb{E}_{t\in{u(0,T)}}\mathbb{E}_{p_t}(\mathbb{x})[\lambda(t)\|\nabla_\mathbb{x}\log p_t(\mathbb{x})-\mathbb{s}_\theta(\mathbf{x},t)\|_2^2]
$$

- $U(0,T)$表示时间间隔内的均匀分布
- $\lambda$是一个正权重函数

一旦我们有了分数函数，便可以将其插入SDE反转过程然后解决它，从而达到取样$x(0)$从原始的数据分布$p_\theta(x)$

![score-based-sde-overview](./%E5%88%86%E6%95%B0%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B.assets/score-based-sde-overview.png)