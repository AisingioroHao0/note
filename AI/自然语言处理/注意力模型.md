# Attention model

## 基本结构

![image-20230511163836425](./%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B.assets/image-20230511163836425.png)

![image-20230511164223790](./%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B.assets/image-20230511164223790.png)

$a^{<t,t'>}$代表了$y^{<t>}$对$a^{<t'>}$的注意力
$$
a^{t,t'}=\frac{exp(e^{<t,t'>})}{\sum_{t'=1}^{Tx}exp(e^{<t,t'>})}
$$
