# 目标检测

检测是否存在目标并输出位置，并输出框住目标的矩形

## 目标定位

输出可以选用$y=(flg,x_w,x_h,w,h,p_1,p_2,...)$

- flg标记是否存在目标
- $x_w,x_h$标记目标存在的位置
- $w,h$为目标矩形的宽和高
- $p_1,...$为是1类目标的概率

## 地标（特征点）检测（Landmark  Detection）

输出$y=(flg,l_{1x},l_{1y},...)$

- $l_{1x},l_{1y}$是关键特征点

## 卷积网络实现滑动窗口

可以使用预先定义的滑动窗口来对目标进行检测

一般滑动窗口将不同位置的截图输入卷积神经网络，可以使用卷积神经网络共享部分运算结果

将全连接层转化为卷积实现，卷积核大小等同于上一层图像的大小，在全连接层使用单个截图检测的卷积核大小

![image-20230406233822499](./%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B.assets/image-20230406233822499.png)

## YOLO

划分图像为互不相交的m\*m小网格，每个网格输出一个向量$t=(p,b_x,b_y,b_h,b_w,c_1,...,c_n)$

- $b_x,b_y$为在该网格中的相对坐标

数据标记则根据检测对象的中心点属于哪个网格而标记



### 交并比

评估目标定位效果可以用交并比来评估：

![image-20230410100313051](./%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B.assets/image-20230410100313051.png)

### non-max Suppression

防止对同一目标有多次检测

对于每一类执行一遍以下操作：

- 过滤概率小于某个阈值的输出
- 选取概率最大的一个检测结果（单元格的输出向量）
- 判断该检测结果与其他检测结果的交并比并根据交并比去除

### anchor box

每一个网格输出多个向量，代表不同的边界框

- 处理多个目标在同一网格的情况
- 检测特殊的同类物体

### 实现

```python
def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = .6):
    """
    去除置信度小于阈值的
    
    Arguments:
        boxes -- tensor of shape (19, 19, 5, 4)
        box_confidence -- tensor of shape (19, 19, 5, 1)
        box_class_probs -- tensor of shape (19, 19, 5, 80)
        threshold -- real value, if [ highest class probability score < threshold],
                     then get rid of the corresponding box

    Returns:
        scores -- tensor of shape (None,), containing the class probability score for selected boxes
        boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w) coordinates of selected boxes
        classes -- tensor of shape (None,), containing the index of the class detected by the selected boxes

    Note: "None" is here because you don't know the exact number of selected boxes, as it depends on the threshold. 
    For example, the actual output size of scores would be (10,) if there are 10 boxes.
    """
    

    box_scores = box_confidence*box_class_probs # 19*19*5*80

    box_classes = tf.argmax(box_scores, axis=-1) # 19*19*5
    box_class_scores = tf.reduce_max(box_scores, axis=-1) # 19*19*5
    

    filtering_mask = box_class_scores >= threshold # 19*19*5
    

    scores = tf.boolean_mask(box_class_scores, filtering_mask)
    boxes = tf.boolean_mask(boxes, filtering_mask)
    classes = tf.boolean_mask(box_classes, filtering_mask)
    
    return scores, boxes, classes
```



```python
def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):
    """
    使用 Non-max suppression (NMS) 去除交并集大于阈值的
    
    Arguments:
    scores -- tensor of shape (None,), output of yolo_filter_boxes()
    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes() that have been scaled to the image size (see later)
    classes -- tensor of shape (None,), output of yolo_filter_boxes()
    max_boxes -- integer, maximum number of predicted boxes you'd like
    iou_threshold -- real value, "intersection over union" threshold used for NMS filtering
    
    Returns:
    scores -- tensor of shape (None, ), predicted score for each box
    boxes -- tensor of shape (None, 4), predicted box coordinates
    classes -- tensor of shape (None, ), predicted class for each box
    
    Note: The "None" dimension of the output tensors has obviously to be less than max_boxes. Note also that this
    function will transpose the shapes of scores, boxes, classes. This is made for convenience.
    """
    
    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()

    nms_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold)
    
    scores = tf.gather(scores, nms_indices)
    boxes = tf.gather(boxes, nms_indices)
    classes = tf.gather(classes, nms_indices)
    
    return scores, boxes, classes
```



```python
def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):
    """
    转换yolo的输出
    
    Arguments:
    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)), contains 4 tensors:
                    box_xy: tensor of shape (None, 19, 19, 5, 2)
                    box_wh: tensor of shape (None, 19, 19, 5, 2)
                    box_confidence: tensor of shape (None, 19, 19, 5, 1)
                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)
    image_shape -- tensor of shape (2,) containing the input shape, in this notebook we use (608., 608.) (has to be float32 dtype)
    max_boxes -- integer, maximum number of predicted boxes you'd like
    score_threshold -- real value, if [ highest class probability score < threshold], then get rid of the corresponding box
    iou_threshold -- real value, "intersection over union" threshold used for NMS filtering
    
    Returns:
    scores -- tensor of shape (None, ), predicted score for each box
    boxes -- tensor of shape (None, 4), predicted box coordinates
    classes -- tensor of shape (None,), predicted class for each box
    """
    

    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs

    boxes = yolo_boxes_to_corners(box_xy, box_wh)

    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, score_threshold)

    boxes = scale_boxes(boxes, image_shape)
    
    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)
    
    return scores, boxes, classes
```



## R-CNN（Regin CNN）

使用分割算法划分区域，在可能的区域上进行滑动窗口目标检测

加速手段：

- 使用卷积网络实现滑动窗口
- 使用卷积神经网络实现分割而非传统分割算法



R-CNN pipeline 结合SVM

### 