# Neural Style Transfer

记原图片为C(content),风格图片为S(style),生成图片为G(generated),

使用内容损失以及风格损失来定义损失函数
$$
J(G)=\alpha J_{content}(C,G)+\beta J_{style}(S,G)
$$

## 内容损失函数

选择某一层的输出值计算损失，通常越浅的层越像素级的近似，越深的层越高级特征近似

如果$a^{[l](G)},a^{[l](C)}$相似，则内容相似
$$
J_{content}(C,G)=\frac{1}{2}||a^{[l](C)}-a^{[l](G)}||^2
$$

## 风格相似损失函数

使用某一层激活值通道见的相关性来表示风格信息$(n_h*n_w)$

通道间的相关性描述了哪一些高层纹理元素倾向于同时或不同时出现

例如某一通道经过可视化最大激活值输出对应的图片区域发现是竖向的边缘信息，另一通道发现是橙色的信息，若相关，则竖向的边缘往往是橙色的



因此使用一个风格矩阵来表示风格信息
$$
G_{kk'}^{[l]}=\sum_i\sum_j a_{ijk}^{[l]}a_{ijk'}^{[l]}
$$

- $a^{[l]}_{ijk}$代表第l层第k个通道第i行第j列的值
- G为gram matrix的意思

损失函数为
$$
J^{[l]}_{style}(S,G)=\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2}\sum_k\sum_{k'}(G^{[l](S)}_{kk'}-G^{[l](G)}_{kk'})
$$
可选择捕获所有特征相关性而非某一层
$$
J_{style}(S,G)=\sum_l \lambda^{[l]}J_{style}^{[l]}(S,G)
$$



## tensorflow实现

### 引入依赖

```python
import os
import sys
import scipy.io
import scipy.misc
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from PIL import Image
import numpy as np
import tensorflow as tf
import pprint

```

### 加载VGG模型，并设置输入尺寸

```python
tf.random.set_seed(272) # DO NOT CHANGE THIS VALUE
pp = pprint.PrettyPrinter(indent=4)
img_size = 400
vgg = tf.keras.applications.VGG19(include_top=False,
                                  input_shape=(img_size, img_size, 3),
                                  weights='pretrained-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')

vgg.trainable = False
pp.pprint(vgg)
```

### 内容损失

```python
def compute_content_cost(content_output, generated_output):
    """
    Computes the content cost
    
    Arguments:
    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C 
    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G
    
    Returns: 
    J_content -- scalar that you compute using equation 1 above.
    """
    a_C = content_output[-1]
    a_G = generated_output[-1]
    
    _, n_H, n_W, n_C = a_G.shape
    
    a_C_unrolled = tf.reshape(a_C,a_C.get_shape().as_list())
    a_G_unrolled = tf.reshape(a_G,a_G.get_shape().as_list())
    
    J_content = tf.reduce_sum((a_C_unrolled-a_G_unrolled)**2)/(4*n_H*n_W*n_C)
    
    
    return J_content
```

### 风格损失

```python
for layer in vgg.layers:
    print(layer.name)
STYLE_LAYERS = [
    ('block1_conv1', 0.2),
    ('block2_conv1', 0.2),
    ('block3_conv1', 0.2),
    ('block4_conv1', 0.2),
    ('block5_conv1', 0.2)]

def gram_matrix(A):
    """
    Argument:
    A -- matrix of shape (n_C, n_H*n_W)
    
    Returns:
    GA -- Gram matrix of A, of shape (n_C, n_C)
    """  
    GA = tf.matmul(A,tf.transpose(A))

    return GA

def compute_layer_style_cost(a_S, a_G):
    """
    Arguments:
    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S 
    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G
    
    Returns: 
    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)
    """

    _, n_H, n_W, n_C = a_G.shape
    

    a_S = tf.transpose(tf.reshape(a_S[0],(n_H*n_W,n_C)))
    a_G = tf.transpose(tf.reshape(a_G[0],(n_H*n_W,n_C)))

    GS = gram_matrix(a_S)
    GG = gram_matrix(a_G)

    J_style_layer = tf.reduce_sum((GS-GG)**2)/(4*n_C**2*(n_H*n_W)**2)
    
    return J_style_layer

def compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):
    """
    Computes the overall style cost from several chosen layers
    
    Arguments:
    style_image_output -- our tensorflow model
    generated_image_output --
    STYLE_LAYERS -- A python list containing:
                        - the names of the layers we would like to extract style from
                        - a coefficient for each of them
    
    Returns: 
    J_style -- tensor representing a scalar value, style cost defined above by equation (2)
    """
    
    # initialize the overall style cost
    J_style = 0

    # Set a_S to be the hidden layer activation from the layer we have selected.
    # The last element of the array contains the content layer image, which must not be used.
    a_S = style_image_output[:-1]

    # Set a_G to be the output of the choosen hidden layers.
    # The last element of the list contains the content layer image which must not be used.
    a_G = generated_image_output[:-1]
    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  
        # Compute style_cost for the current layer
        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])

        # Add weight * J_style_layer of this layer to overall style cost
        J_style += weight[1] * J_style_layer

    return J_style

```

### 定义损失函数

```python
@tf.function()
def total_cost(J_content, J_style, alpha = 10, beta = 40):
    """
    Computes the total cost function
    
    Arguments:
    J_content -- content cost coded above
    J_style -- style cost coded above
    alpha -- hyperparameter weighting the importance of the content cost
    beta -- hyperparameter weighting the importance of the style cost
    
    Returns:
    J -- total cost as defined by the formula above.
    """
    J = alpha*J_content+beta*J_style
    return J
```

### 加载风格图片

```python
style_image =  np.array(Image.open("images/monet.jpg").resize((img_size, img_size)))
style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))
print(style_image.shape)
imshow(style_image[0])
plt.show()
```

### 随机生成图片

```python
generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))
noise = tf.random.uniform(tf.shape(generated_image), -0.25, 0.25)
generated_image = tf.add(generated_image, noise)
generated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)

print(generated_image.shape)
imshow(generated_image.numpy()[0])
plt.show()
```

### 训练

```python
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

@tf.function()
def train_step(generated_image):
    with tf.GradientTape() as tape:
        a_G = vgg_model_outputs(generated_image)
        
        J_style = compute_style_cost(a_S,a_G)

        J_content = compute_content_cost(a_C,a_G)
        J = total_cost(J_content, J_style)
        
    grad = tape.gradient(J, generated_image)

    optimizer.apply_gradients([(grad, generated_image)])
    generated_image.assign(clip_0_1(generated_image))
  
    return J

generated_image = tf.Variable(generated_image)

train_step_test(train_step, generated_image)

epochs = 2501
for i in range(epochs):
    train_step(generated_image)
    if i % 250 == 0:
        print(f"Epoch {i} ")
    if i % 250 == 0:
        image = tensor_to_image(generated_image)
        imshow(image)
        image.save(f"output/image_{i}.jpg")
        plt.show() 

```

