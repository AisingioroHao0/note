# 概率论

## 先验概率与后验概率

先验概率：根据统计得到的概率

后验概率：根据先验概率计算得到的概率。试验（某个事件发生）后的概率

## 概率分布

用于表述随机变量取值的概率规律

如果实验结果用变量X的取值来表示，则随机试验的概率分布就是随机变量的概率概率分布。

## 指示函数

返回一个0或1
$$
I=(y_i=c_k)
$$

## 共轭

在[贝叶斯统计](https://zh.wikipedia.org/wiki/贝叶斯统计)中，如果[后验分布](https://zh.wikipedia.org/wiki/後驗分布)与[先验分布](https://zh.wikipedia.org/wiki/先驗分布)属于同类，则先验分布与后验分布被称为**共轭分布**，而先验分布被称为似然函数的**共轭先验**（Conjugate prior）。

## 频率派和贝叶斯派

频率派来讲，一个模型的参数是固定的，而数据是在分布中随机采样。相信这个分布的参数不管如何采样，根据参数对其的估计都应该是不会变的



贝叶斯派来讲，数据是固定的，模型的参数才是一直变化的，我们不停的观察数据，估计出来的模型参数就可能一直变化。

模型参数可能会有一个最初的信仰，称为先验假设。

对于贝叶斯派，有公式

![image-20230313171526342](./%E6%A6%82%E7%8E%87%E8%AE%BA.assets/image-20230313171526342.png)

$P\{\theta|D\}$称为后验概率分布，指由观察数据和先验假设推测出来的参数分布。

$P\{\theta\}$称为先验分布，指的是对于参数的专家只是或者假设引入的知识，可指导参数$\theta$学习。

而$P\{D|\theta\}$称为似然函数，指的就是由于观察数据导致的参数更新。

![image-20230313172019673](./%E6%A6%82%E7%8E%87%E8%AE%BA.assets/image-20230313172019673.png)



贝叶斯规则是概率统计中的应用所观察到的现象对有关概率分布的主观判断（先验概率）进行修正的方法。

贝叶斯公式是当分析样本大到接近总体数时，样本中时间发生的概率将接近于总体中事件发生的概率。



个人认为，贝叶斯公式即在A前提下发生B的概率和在B前提下发生A的概率是相等的。

因此，当我们有了预测用的基础数据data，想要预测的目标p，根据有标注p的训练集即可得到$P(p|data)$

## 正态分布

### 运算

$$
N(0,\sigma^2_1I)+N(0,\sigma^2_2I) \sim N(0,(\sigma^2_1+\sigma^2_2)I)
$$

## 信息论

### KL散度

又称为相对熵，互熵，鉴别信息，Kullback熵。

KL散度是非对称的$D(P||Q)\ne D(Q||P)$

离散随机变量的交叉熵定义为
$$
H(p,q)=\sum_x p(x)log\frac{1}{q(x)}
$$
连续随机变量的交叉熵定义为
$$
D(P||Q)=\int_x p(x)*log(\frac{P(i)}{Q(i)})dx
$$
KL散度可以用来衡量两个分布之间的差异程度。两者cha'yiKL散度越小
